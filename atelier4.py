# -*- coding: utf-8 -*-
"""atelier4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XFXLzXbTPgEBsnnK70UaBQxyvR0f_yNT
"""

# Imports n√©cessaires
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import torchvision.utils as vutils

import numpy as np
import matplotlib.pyplot as plt
import os

# V√©rification GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device utilis√© : {device}")

# ============================================================================
# PART 1: AUTO-ENCODER (AE) AND VARIATIONAL AUTO-ENCODER (VAE)
# ============================================================================

# ============================================================================
# STEP 2: LOAD AND PREPARE MNIST DATASET
# ============================================================================
# Question: What is MNIST dataset?
# Answer: MNIST contains 70,000 grayscale images of handwritten digits (0-9)
#         Each image is 28x28 pixels
#         60,000 for training, 10,000 for testing

# Hyperparameters for data loading
batch_size = 128  # Number of images processed together

# Question: Why do we normalize images to [-1, 1]?
# Answer: Normalization helps neural networks train faster and more stably
#         The range [-1, 1] works well with Tanh activation in the decoder
transform = transforms.Compose([
    transforms.ToTensor(),  # Convert PIL Image to tensor [0, 1]
    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]
])

# Load MNIST dataset
train_dataset = torchvision.datasets.MNIST(
    root='./data',
    train=True,
    download=True,
    transform=transform
)
test_dataset = torchvision.datasets.MNIST(
    root='./data',
    train=False,
    download=True,
    transform=transform
)

# Create data loaders
# Question: What is a DataLoader?
# Answer: DataLoader handles batching, shuffling, and parallel data loading
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=False)

# Visualize a batch of MNIST images
imgs, labels = next(iter(train_loader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Sample MNIST Images")
plt.imshow(np.transpose(
    vutils.make_grid(imgs[:64], padding=2, normalize=True).cpu(),
    (1, 2, 0)
))
plt.show()

# ============================================================================
# STEP 3: BUILD AUTO-ENCODER (AE) ARCHITECTURE
# ============================================================================
# Question: What is an Auto-Encoder?
# Answer: An AE compresses input data into a lower-dimensional latent space
#         (encoder), then reconstructs it (decoder). It learns efficient
#         data representations without labels (unsupervised learning).

# Hyperparameters
latent_dim = 2  # Dimension of compressed representation (2D for visualization)
lr_ae = 1e-3    # Learning rate
epochs_ae = 30  # Number of training epochs

# Question: Why use latent_dim = 2?
# Answer: 2D allows us to visualize the latent space as a scatter plot
#         In practice, higher dimensions (32, 64, 128) capture more information

class AutoEncoder(nn.Module):
    """
    Auto-Encoder Architecture:
    - Encoder: 784 -> 256 -> 64 -> 2 (compression)
    - Decoder: 2 -> 64 -> 256 -> 784 (reconstruction)
    """
    def __init__(self):
        super().__init__()

        # Encoder: compresses 28x28=784 pixels to latent_dim dimensions
        # Question: Why use ReLU activation?
        # Answer: ReLU is fast, avoids vanishing gradients, and works well
        self.encoder = nn.Sequential(
            nn.Linear(784, 256),  # First compression layer
            nn.ReLU(),
            nn.Linear(256, 64),   # Second compression layer
            nn.ReLU(),
            nn.Linear(64, latent_dim)  # Final compression to 2D
        )

        # Decoder: reconstructs from latent space back to 784 pixels
        # Question: Why Tanh at the end?
        # Answer: Tanh outputs [-1, 1], matching our normalized input range
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 256),
            nn.ReLU(),
            nn.Linear(256, 784),
            nn.Tanh()  # Output range [-1, 1]
        )

    def forward(self, x):
        """Forward pass: encode then decode"""
        x = x.view(-1, 784)  # Flatten image to vector
        z = self.encoder(x)   # Encode to latent space
        x_recon = self.decoder(z)  # Decode back to image
        return x_recon.view(-1, 1, 28, 28), z  # Reshape and return

# Initialize model, loss function, and optimizer
ae = AutoEncoder().to(device)

# Question: Why use MSE (Mean Squared Error) loss?
# Answer: MSE measures pixel-wise difference between original and reconstructed
#         images. Good for continuous outputs.
criterion_ae = nn.MSELoss()

# Question: What is Adam optimizer?
# Answer: Adam is an adaptive optimizer that adjusts learning rates per parameter
#         It's robust and works well for most deep learning problems
optimizer_ae = optim.Adam(ae.parameters(), lr=lr_ae)

# ============================================================================
# STEP 4: TRAIN AUTO-ENCODER
# ============================================================================
# Question: What happens during training?
# Answer: The model learns to minimize reconstruction error by adjusting weights
#         through backpropagation

ae_losses = []  # Track loss over epochs

print("\n" + "="*60)
print("TRAINING AUTO-ENCODER")
print("="*60)

for epoch in range(epochs_ae):
    ae.train()  # Set to training mode
    epoch_loss = 0

    # Iterate through batches
    for data, _ in train_loader:
        data = data.to(device)  # Move data to GPU

        # Forward pass
        recon, _ = ae(data)
        loss = criterion_ae(recon, data)

        # Backward pass
        optimizer_ae.zero_grad()  # Clear previous gradients
        loss.backward()           # Compute gradients
        optimizer_ae.step()       # Update weights

        epoch_loss += loss.item()

    # Calculate and store average loss
    avg_loss = epoch_loss / len(train_loader)
    ae_losses.append(avg_loss)

    if (epoch + 1) % 5 == 0:  # Print every 5 epochs
        print(f"Epoch {epoch+1}/{epochs_ae} - Loss: {avg_loss:.6f}")

# Plot training loss
plt.figure(figsize=(8, 5))
plt.plot(ae_losses, marker='o')
plt.title("Auto-Encoder Training Loss")
plt.xlabel("Epoch")
plt.ylabel("MSE Loss")
plt.grid(True)
plt.show()

# STEP 5: BUILD VARIATIONAL AUTO-ENCODER (VAE) ARCHITECTURE
# ============================================================================
# Question: How is VAE different from AE?
# Answer: VAE learns a probability distribution in latent space instead of
#         deterministic encoding. It uses:
#         1. Reparameterization trick: z = Œº + œÉ * Œµ (Œµ ~ N(0,1))
#         2. KL divergence loss to regularize the latent space

import torch
import torch.nn as nn
import torch.optim as optim

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# =========================
# Hyperparameters
# =========================
lr_vae = 1e-3
epochs_vae = 30
beta = 1.0          # Weight for KL divergence loss (Œ≤-VAE)
latent_dim = 20     # üîß FIX: latent space dimension

# =========================
# VAE Model Definition
# =========================
class VAE(nn.Module):
    """
    Variational Auto-Encoder Architecture:
    - Encoder outputs mean (Œº) and log-variance (log œÉ¬≤)
    - Sampling from N(Œº, œÉ¬≤) using reparameterization trick
    - Decoder reconstructs from sampled latent variable
    """
    def __init__(self):
        super().__init__()

        # Encoder layers
        self.enc1 = nn.Linear(784, 256)
        self.enc2 = nn.Linear(256, 64)

        # Latent space parameters
        # Why logvar?
        # log(œÉ¬≤) guarantees variance is always positive
        self.mu = nn.Linear(64, latent_dim)
        self.logvar = nn.Linear(64, latent_dim)

        # Decoder layers
        self.dec1 = nn.Linear(latent_dim, 64)
        self.dec2 = nn.Linear(64, 256)
        self.dec3 = nn.Linear(256, 784)

    def encode(self, x):
        """Encode input to latent distribution parameters"""
        h = torch.relu(self.enc1(x))
        h = torch.relu(self.enc2(h))
        return self.mu(h), self.logvar(h)

    def reparameterize(self, mu, logvar):
        """
        Reparameterization trick:
        z = Œº + œÉ * Œµ, where Œµ ~ N(0,1)
        """
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z):
        """Decode latent variable to reconstruction"""
        h = torch.relu(self.dec1(z))
        h = torch.relu(self.dec2(h))
        return torch.tanh(self.dec3(h))

    def forward(self, x):
        """Full forward pass: encode ‚Üí sample ‚Üí decode"""
        x = x.view(-1, 784)
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        recon = self.decode(z)
        return recon.view(-1, 1, 28, 28), mu, logvar


# =========================
# VAE Loss Function
# =========================
def vae_loss(recon, x, mu, logvar):
    """
    VAE Loss = Reconstruction Loss + Œ≤ * KL Divergence

    KL divergence:
    KL = -0.5 * Œ£(1 + log(œÉ¬≤) - Œº¬≤ - œÉ¬≤)
    """
    # Reconstruction loss
    recon_loss = nn.functional.mse_loss(recon, x, reduction='sum')

    # KL divergence loss
    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())

    return (recon_loss + beta * kl_loss) / x.size(0)


# =========================
# Model & Optimizer
# =========================
vae = VAE().to(device)
optimizer_vae = optim.Adam(vae.parameters(), lr=lr_vae)

# ============================================================================
# STEP 0: DATASET & DATALOADER (REQUIRED BEFORE TRAINING)
# ============================================================================

from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Transform: normalize to [-1, 1] because decoder uses tanh
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Load MNIST dataset
train_dataset = datasets.MNIST(
    root="./data",
    train=True,
    download=True,
    transform=transform
)

# DataLoader
batch_size = 128
train_loader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True
)

# ============================================================================
# DEEP LEARNING LAB 4 - PART 1: AUTO-ENCODERS (AE & VAE)
# Complete Standalone Version - Run cells in order!
# ============================================================================

# ============================================================================
# STEP 1: IMPORTS AND SETUP
# ============================================================================
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import torchvision.utils as vutils

import numpy as np
import matplotlib.pyplot as plt

# GPU Setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")

# ============================================================================
# STEP 2: LOAD MNIST DATASET
# ============================================================================
batch_size = 128

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=False)

# Visualize
imgs, _ = next(iter(train_loader))
plt.figure(figsize=(8, 8))
plt.axis("off")
plt.title("Sample MNIST Images")
plt.imshow(np.transpose(vutils.make_grid(imgs[:64], padding=2, normalize=True).cpu(), (1, 2, 0)))
plt.show()

# ============================================================================
# STEP 3: BUILD AUTO-ENCODER (AE)
# ============================================================================
print("\n" + "="*60)
print("BUILDING AUTO-ENCODER")
print("="*60)

latent_dim = 2
lr_ae = 1e-3
epochs_ae = 30

class AutoEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 256),
            nn.ReLU(),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, latent_dim)
        )
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 256),
            nn.ReLU(),
            nn.Linear(256, 784),
            nn.Tanh()
        )

    def forward(self, x):
        x = x.view(-1, 784)
        z = self.encoder(x)
        x_recon = self.decoder(z)
        return x_recon.view(-1, 1, 28, 28), z

ae = AutoEncoder().to(device)
criterion_ae = nn.MSELoss()
optimizer_ae = optim.Adam(ae.parameters(), lr=lr_ae)

print(f"‚úì Auto-Encoder built")
print(f"  Parameters: {sum(p.numel() for p in ae.parameters()):,}")

# ============================================================================
# STEP 4: TRAIN AUTO-ENCODER
# ============================================================================
print("\n" + "="*60)
print("TRAINING AUTO-ENCODER")
print("="*60)

ae_losses = []

for epoch in range(epochs_ae):
    ae.train()
    epoch_loss = 0

    for data, _ in train_loader:
        data = data.to(device)
        recon, _ = ae(data)
        loss = criterion_ae(recon, data)

        optimizer_ae.zero_grad()
        loss.backward()
        optimizer_ae.step()

        epoch_loss += loss.item()

    avg_loss = epoch_loss / len(train_loader)
    ae_losses.append(avg_loss)

    if (epoch + 1) % 5 == 0:
        print(f"Epoch {epoch+1}/{epochs_ae} - Loss: {avg_loss:.6f}")

plt.figure(figsize=(8, 5))
plt.plot(ae_losses, marker='o')
plt.title("Auto-Encoder Training Loss")
plt.xlabel("Epoch")
plt.ylabel("MSE Loss")
plt.grid(True)
plt.show()

print("‚úì Auto-Encoder training complete")

# ============================================================================
# STEP 5: BUILD VARIATIONAL AUTO-ENCODER (VAE)
# ============================================================================
print("\n" + "="*60)
print("BUILDING VARIATIONAL AUTO-ENCODER")
print("="*60)

lr_vae = 1e-3
epochs_vae = 30
beta = 1.0

class VAE(nn.Module):
    def __init__(self):
        super().__init__()
        self.enc1 = nn.Linear(784, 256)
        self.enc2 = nn.Linear(256, 64)
        self.mu = nn.Linear(64, latent_dim)
        self.logvar = nn.Linear(64, latent_dim)

        self.dec1 = nn.Linear(latent_dim, 64)
        self.dec2 = nn.Linear(64, 256)
        self.dec3 = nn.Linear(256, 784)

    def encode(self, x):
        h = torch.relu(self.enc1(x))
        h = torch.relu(self.enc2(h))
        return self.mu(h), self.logvar(h)

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z):
        h = torch.relu(self.dec1(z))
        h = torch.relu(self.dec2(h))
        return torch.tanh(self.dec3(h))

    def forward(self, x):
        x = x.view(-1, 784)
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        recon = self.decode(z)
        return recon.view(-1, 1, 28, 28), mu, logvar

def vae_loss(recon, x, mu, logvar):
    recon_loss = nn.functional.mse_loss(recon, x, reduction='sum')
    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return (recon_loss + beta * kl_loss) / x.size(0)

vae = VAE().to(device)
optimizer_vae = optim.Adam(vae.parameters(), lr=lr_vae)

print(f"‚úì VAE built")
print(f"  Parameters: {sum(p.numel() for p in vae.parameters()):,}")

# ============================================================================
# STEP 6: TRAIN VARIATIONAL AUTO-ENCODER
# ============================================================================
print("\n" + "="*60)
print("TRAINING VARIATIONAL AUTO-ENCODER")
print("="*60)

vae_losses = []
kl_losses = []

for epoch in range(epochs_vae):
    vae.train()
    total_loss = 0
    total_kl = 0

    for data, _ in train_loader:
        data = data.to(device)
        recon, mu, logvar = vae(data)
        loss = vae_loss(recon, data, mu, logvar)

        kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / data.size(0)
        total_kl += kl.item()

        optimizer_vae.zero_grad()
        loss.backward()
        optimizer_vae.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    avg_kl = total_kl / len(train_loader)
    vae_losses.append(avg_loss)
    kl_losses.append(avg_kl)

    if (epoch + 1) % 5 == 0:
        print(f"Epoch {epoch+1}/{epochs_vae} - Total Loss: {avg_loss:.6f} - KL: {avg_kl:.6f}")

print("‚úì VAE training complete")

# ============================================================================
# STEP 7: COMPARE AE AND VAE LOSSES
# ============================================================================
print("\n" + "="*60)
print("EVALUATION: COMPARING AE vs VAE")
print("="*60)

plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
plt.plot(ae_losses, label="AE Loss (MSE only)", marker='o')
plt.plot(vae_losses, label="VAE Total Loss (MSE + KL)", marker='s')
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Loss Comparison: AE vs VAE")
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(kl_losses, label="KL Divergence", marker='^', color='red')
plt.xlabel("Epoch")
plt.ylabel("KL Divergence")
plt.title("VAE KL Divergence Over Training")
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

print("\nCONCLUSIONS:")
print("1. AE: Lower loss, deterministic encoding, discrete latent space")
print("2. VAE: Higher loss (due to KL), probabilistic encoding, continuous latent space")
print("3. VAE's latent space is more structured and suitable for generation")
print("4. KL divergence ensures smooth latent space interpolation")

# ============================================================================
# STEP 8: VISUALIZE LATENT SPACES
# ============================================================================
print("\n" + "="*60)
print("VISUALIZING LATENT SPACES")
print("="*60)

def get_latent_space(model, loader, is_vae=False):
    model.eval()
    zs = []
    labels = []
    with torch.no_grad():
        for data, lbl in loader:
            data = data.to(device)
            if is_vae:
                _, mu, _ = model(data)
                zs.append(mu.cpu().numpy())
            else:
                _, z = model(data)
                zs.append(z.cpu().numpy())
            labels.append(lbl.numpy())
    return np.concatenate(zs), np.concatenate(labels)

ae_z, ae_y = get_latent_space(ae, test_loader)
vae_z, vae_y = get_latent_space(vae, test_loader, is_vae=True)

plt.figure(figsize=(15, 6))

plt.subplot(1, 2, 1)
scatter = plt.scatter(ae_z[:, 0], ae_z[:, 1], c=ae_y, cmap='tab10', alpha=0.7, s=5)
plt.colorbar(scatter, label='Digit')
plt.title("Auto-Encoder Latent Space (2D)")
plt.xlabel("Latent Dimension 1")
plt.ylabel("Latent Dimension 2")
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
scatter = plt.scatter(vae_z[:, 0], vae_z[:, 1], c=vae_y, cmap='tab10', alpha=0.7, s=5)
plt.colorbar(scatter, label='Digit')
plt.title("Variational Auto-Encoder Latent Space (2D)")
plt.xlabel("Latent Dimension 1")
plt.ylabel("Latent Dimension 2")
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\nLATENT SPACE ANALYSIS:")
print("‚Ä¢ AE: More discrete clusters, less overlap between digit classes")
print("‚Ä¢ VAE: Smoother, more continuous space with some overlap")
print("‚Ä¢ VAE's structure allows for better interpolation and generation")

# ============================================================================
# STEP 9: RECONSTRUCTION COMPARISON
# ============================================================================
print("\n" + "="*60)
print("RECONSTRUCTION QUALITY COMPARISON")
print("="*60)

# Get test samples
test_imgs, _ = next(iter(test_loader))
test_imgs = test_imgs[:8].to(device)

# Reconstruct with both models
ae.eval()
vae.eval()
with torch.no_grad():
    ae_recon, _ = ae(test_imgs)
    vae_recon, _, _ = vae(test_imgs)

# Visualize
fig, axes = plt.subplots(3, 8, figsize=(16, 6))
fig.suptitle('Reconstruction Comparison', fontsize=14, fontweight='bold')

for i in range(8):
    # Original
    axes[0, i].imshow(test_imgs[i, 0].cpu(), cmap='gray')
    axes[0, i].axis('off')
    if i == 0:
        axes[0, i].set_title('Original', fontsize=10, fontweight='bold')

    # AE reconstruction
    axes[1, i].imshow(ae_recon[i, 0].cpu(), cmap='gray')
    axes[1, i].axis('off')
    if i == 0:
        axes[1, i].set_title('AE Recon', fontsize=10, fontweight='bold')

    # VAE reconstruction
    axes[2, i].imshow(vae_recon[i, 0].cpu(), cmap='gray')
    axes[2, i].axis('off')
    if i == 0:
        axes[2, i].set_title('VAE Recon', fontsize=10, fontweight='bold')

plt.tight_layout()
plt.show()

print("\nRECONSTRUCTION QUALITY:")
print("‚Ä¢ AE: Sharper reconstructions, better pixel-wise accuracy")
print("‚Ä¢ VAE: Slightly blurrier, but maintains digit structure")
print("‚Ä¢ Trade-off: AE optimizes reconstruction, VAE optimizes generation capability")

# ============================================================================
# STEP 10: GENERATE NEW SAMPLES FROM VAE
# ============================================================================
print("\n" + "="*60)
print("GENERATING NEW SAMPLES FROM VAE LATENT SPACE")
print("="*60)

vae.eval()
with torch.no_grad():
    # Sample from standard normal distribution
    z = torch.randn(64, latent_dim).to(device)
    generated = vae.decode(z).view(-1, 1, 28, 28).cpu()

plt.figure(figsize=(10, 10))
plt.axis("off")
plt.title("Samples Generated from VAE Latent Space")
grid = vutils.make_grid(generated, padding=2, normalize=True, nrow=8)
plt.imshow(np.transpose(grid, (1, 2, 0)), cmap='gray')
plt.show()

print("‚úì VAE can generate new digit-like images by sampling from N(0,1)")

# ============================================================================
# STEP 11: LATENT SPACE INTERPOLATION
# ============================================================================
print("\n" + "="*60)
print("LATENT SPACE INTERPOLATION")
print("="*60)

vae.eval()
with torch.no_grad():
    # Get two random points in latent space
    z1 = torch.randn(1, latent_dim).to(device)
    z2 = torch.randn(1, latent_dim).to(device)

    # Interpolate between them
    num_steps = 10
    interpolations = []
    for alpha in np.linspace(0, 1, num_steps):
        z_interp = (1 - alpha) * z1 + alpha * z2
        img = vae.decode(z_interp).view(1, 28, 28).cpu()
        interpolations.append(img)

# Visualize interpolation
fig, axes = plt.subplots(1, num_steps, figsize=(15, 2))
fig.suptitle('Latent Space Interpolation (VAE)', fontweight='bold')
for i, img in enumerate(interpolations):
    axes[i].imshow(img[0], cmap='gray')
    axes[i].axis('off')
plt.tight_layout()
plt.show()

print("‚úì VAE produces smooth transitions between digits")
print("  This demonstrates the continuous nature of VAE's latent space")

# ============================================================================
# FINAL SUMMARY
# ============================================================================
print("\n" + "="*70)
print("PART 1 COMPLETE - SUMMARY")
print("="*70)
print("""
‚úì COMPLETED TASKS:
1. Built and trained Auto-Encoder (AE) on MNIST
2. Built and trained Variational Auto-Encoder (VAE) on MNIST
3. Compared losses: AE vs VAE (+ KL Divergence analysis)
4. Visualized 2D latent spaces for both models
5. Compared reconstruction quality
6. Generated new samples from VAE
7. Demonstrated latent space interpolation

KEY FINDINGS:
‚Ä¢ AE: Better reconstruction, discrete latent space
‚Ä¢ VAE: Better generation, continuous latent space with smooth interpolation
‚Ä¢ VAE uses KL divergence to regularize latent space structure
‚Ä¢ Trade-off: Reconstruction quality vs Generative capability

EXAM TIP: Understand the difference between deterministic (AE)
and probabilistic (VAE) encoding, and why VAE is better for generation!
""")
print("="*70)

# ============================================================================
# DEEP LEARNING LAB 4 - PART 2: GANs (KAGGLE DATASET FIX)
# ============================================================================

# ============================================================================
# STEP 1: IMPORTS AND SETUP
# ============================================================================
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import torchvision.utils as vutils

import numpy as np
import matplotlib.pyplot as plt
import os

# GPU Setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")

# ============================================================================
# STEP 2: DOWNLOAD ABSTRACT ART DATASET FROM KAGGLE
# ============================================================================
print("\n" + "="*60)
print("DATASET SETUP - ABSTRACT ART GALLERY")
print("="*60)

# Check if dataset already exists
if os.path.exists('abstract_art') and os.path.isdir('abstract_art'):
    print("‚úÖ Dataset folder 'abstract_art' already exists!")

    # Check if it has images
    subdirs = [d for d in os.listdir('abstract_art') if os.path.isdir(os.path.join('abstract_art', d))]
    if len(subdirs) > 0:
        print(f"‚úÖ Found {len(subdirs)} subdirectories with images")
    else:
        print("‚ö†Ô∏è  Folder exists but appears empty!")

else:
    print("üì• Dataset not found. Downloading from Kaggle...")
    print("\n" + "="*60)
    print("KAGGLE SETUP INSTRUCTIONS:")
    print("="*60)
    print("\n1Ô∏è‚É£  Get your Kaggle API credentials:")
    print("   ‚Ä¢ Go to: https://www.kaggle.com/settings")
    print("   ‚Ä¢ Scroll to 'API' section")
    print("   ‚Ä¢ Click 'Create New Token'")
    print("   ‚Ä¢ This downloads kaggle.json")
    print("\n2Ô∏è‚É£  Upload kaggle.json when prompted below")
    print("="*60 + "\n")

    # Check if in Colab
    try:
        from google.colab import files
        IN_COLAB = True
    except:
        IN_COLAB = False
        print("‚ùå Not running in Google Colab!")
        print("   Please upload dataset manually or run in Colab")
        raise RuntimeError("This download method requires Google Colab")

    # Upload kaggle.json
    print("üëá Click 'Choose Files' below and upload your kaggle.json:")
    uploaded = files.upload()

    if 'kaggle.json' not in uploaded:
        print("‚ùå kaggle.json not found in uploaded files!")
        raise FileNotFoundError("Please upload kaggle.json")

    print("\n‚úÖ kaggle.json uploaded successfully!")

    # Setup Kaggle API
    print("‚öôÔ∏è  Setting up Kaggle API...")
    get_ipython().system('mkdir -p ~/.kaggle')
    get_ipython().system('cp kaggle.json ~/.kaggle/')
    get_ipython().system('chmod 600 ~/.kaggle/kaggle.json')
    print("‚úÖ Kaggle API configured")

    # Download dataset
    print("\nüì¶ Downloading Abstract Art Gallery dataset...")
    print("   (This may take 2-5 minutes depending on connection)")
    result = get_ipython().system('kaggle datasets download -d bryanb/abstract-art-gallery')

    # Check if download succeeded
    if not os.path.exists('abstract-art-gallery.zip'):
        print("\n‚ùå ERROR: Download failed!")
        print("   Please check:")
        print("   1. Your Kaggle API token is valid")
        print("   2. You have internet connection")
        print("   3. Dataset URL is correct")
        raise FileNotFoundError("Failed to download dataset from Kaggle")

    print("‚úÖ Download complete!")

    # Extract dataset
    print("\nüìÇ Extracting files...")
    get_ipython().system('unzip -q abstract-art-gallery.zip -d abstract_art_temp')

    # Move files to correct location
    # The dataset might be in a subdirectory
    if os.path.exists('abstract_art_temp/Abstract_gallery'):
        get_ipython().system('mv abstract_art_temp/Abstract_gallery abstract_art')
        get_ipython().system('rm -rf abstract_art_temp')
    elif os.path.exists('abstract_art_temp'):
        get_ipython().system('mv abstract_art_temp abstract_art')

    # Verify extraction
    if os.path.exists('abstract_art'):
        print("‚úÖ Dataset extracted successfully!")
        get_ipython().system('ls -lh abstract_art/ | head -10')
    else:
        print("‚ùå ERROR: Extraction failed!")
        raise FileNotFoundError("Dataset folder not created after extraction")

    # Clean up
    if os.path.exists('abstract-art-gallery.zip'):
        get_ipython().system('rm abstract-art-gallery.zip')
        print("üßπ Cleaned up zip file")

print("\n" + "="*60)
print("DATASET READY!")
print("="*60)

# ============================================================================
# STEP 3: CONFIGURE DATA LOADER
# ============================================================================
print("\n" + "="*60)
print("QUESTION 1: CONFIGURE DATA LOADER")
print("="*60)

# Hyperparameters
img_size = 64
batch_size_gan = 64

# Question: Why normalize to [-1, 1]?
# Answer: Matches the Tanh output range in Generator
transform_gan = transforms.Compose([
    transforms.Resize(img_size),
    transforms.CenterCrop(img_size),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

print("\nüé® Loading Abstract Art dataset...")

# Load dataset
try:
    dataset_gan = torchvision.datasets.ImageFolder(
        root='abstract_art',
        transform=transform_gan
    )

    dataloader_gan = DataLoader(
        dataset_gan,
        batch_size=batch_size_gan,
        shuffle=True,
        num_workers=2,
        pin_memory=True
    )

    print(f"\n‚úÖ Dataset loaded successfully!")
    print(f"   Total images: {len(dataset_gan)}")
    print(f"   Image size: {img_size}√ó{img_size}")
    print(f"   Channels: 3 (RGB)")
    print(f"   Batch size: {batch_size_gan}")
    print(f"   Batches per epoch: {len(dataloader_gan)}")

except Exception as e:
    print(f"\n‚ùå ERROR loading dataset: {e}")
    print("\nDataset structure should be:")
    print("abstract_art/")
    print("  ‚îî‚îÄ‚îÄ class_folder/")
    print("      ‚îú‚îÄ‚îÄ image1.jpg")
    print("      ‚îú‚îÄ‚îÄ image2.jpg")
    print("      ‚îî‚îÄ‚îÄ ...")
    raise

# Visualize real samples
print("\nüñºÔ∏è  Displaying sample images...")
real_batch = next(iter(dataloader_gan))[0]
plt.figure(figsize=(10, 10))
plt.axis("off")
plt.title("Real Abstract Art Examples", fontsize=14, fontweight='bold')
plt.imshow(np.transpose(
    vutils.make_grid(real_batch[:64], padding=2, normalize=True).cpu(),
    (1, 2, 0)
))
plt.show()

print("‚úÖ Data loader configured successfully!")

# ============================================================================
# QUESTION 1: DEFINE GENERATOR ARCHITECTURE
# ============================================================================
print("\n" + "="*60)
print("QUESTION 1: DEFINE GENERATOR")
print("="*60)

nz = 100  # Noise vector dimension
nc = 3    # Number of channels (RGB)
lr_gan = 0.0002
beta1 = 0.5
epochs_gan = 100

class Generator(nn.Module):
    """
    DCGAN Generator Architecture

    Question: What does the Generator do?
    Answer: Transforms random noise (100D vector) into realistic images (3√ó64√ó64)

    Question: Why use ConvTranspose2d?
    Answer: Upsamples spatial dimensions progressively
            1√ó1 ‚Üí 4√ó4 ‚Üí 8√ó8 ‚Üí 16√ó16 ‚Üí 32√ó32 ‚Üí 64√ó64
    """
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            # Layer 1: (100, 1, 1) ‚Üí (512, 4, 4)
            nn.ConvTranspose2d(nz, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),

            # Layer 2: (512, 4, 4) ‚Üí (256, 8, 8)
            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            # Layer 3: (256, 8, 8) ‚Üí (128, 16, 16)
            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            # Layer 4: (128, 16, 16) ‚Üí (64, 32, 32)
            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),

            # Layer 5: (64, 32, 32) ‚Üí (3, 64, 64)
            nn.ConvTranspose2d(64, nc, 4, 2, 1, bias=False),
            nn.Tanh()  # Output range: [-1, 1]
        )

    def forward(self, x):
        return self.main(x)

print("‚úÖ Generator defined")
print("   Input: Noise vector (100D)")
print("   Output: RGB image (3√ó64√ó64)")
print("   Architecture: 5 ConvTranspose2d layers with BatchNorm")

# ============================================================================
# QUESTION 1: DEFINE DISCRIMINATOR ARCHITECTURE
# ============================================================================
print("\n" + "="*60)
print("QUESTION 1: DEFINE DISCRIMINATOR")
print("="*60)

class Discriminator(nn.Module):
    """
    DCGAN Discriminator Architecture

    Question: What does the Discriminator do?
    Answer: Classifies images as real (1) or fake (0)

    Question: Why LeakyReLU instead of ReLU?
    Answer: Allows small negative gradients, prevents "dying neurons"
    """
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            # Layer 1: (3, 64, 64) ‚Üí (64, 32, 32)
            nn.Conv2d(nc, 64, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),

            # Layer 2: (64, 32, 32) ‚Üí (128, 16, 16)
            nn.Conv2d(64, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            # Layer 3: (128, 16, 16) ‚Üí (256, 8, 8)
            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            # Layer 4: (256, 8, 8) ‚Üí (512, 4, 4)
            nn.Conv2d(256, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),

            # Layer 5: (512, 4, 4) ‚Üí (1, 1, 1)
            nn.Conv2d(512, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()  # Output: probability [0, 1]
        )

    def forward(self, x):
        return self.main(x).view(-1)

print("‚úÖ Discriminator defined")
print("   Input: RGB image (3√ó64√ó64)")
print("   Output: Probability [0, 1]")
print("   Architecture: 5 Conv2d layers with BatchNorm")

# ============================================================================
# QUESTION 1: INITIALIZE MODELS & GPU SETTING
# ============================================================================
print("\n" + "="*60)
print("QUESTION 1: INITIALIZE MODELS & GPU SETTING")
print("="*60)

# Initialize and move to GPU
netG = Generator().to(device)
netD = Discriminator().to(device)

def weights_init(m):
    """
    Question: Why initialize weights properly?
    Answer: Prevents vanishing/exploding gradients, helps convergence
    """
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

# Apply weight initialization
netG.apply(weights_init)
netD.apply(weights_init)

print(f"‚úÖ Models initialized and moved to: {device}")
print(f"   Generator parameters: {sum(p.numel() for p in netG.parameters()):,}")
print(f"   Discriminator parameters: {sum(p.numel() for p in netD.parameters()):,}")

# ============================================================================
# QUESTION 1: DEFINE LOSS FUNCTION
# ============================================================================
print("\n" + "="*60)
print("QUESTION 1: DEFINE LOSS FUNCTION")
print("="*60)

criterion = nn.BCELoss()

print("‚úÖ Loss function: Binary Cross Entropy (BCE)")
print("   Formula: -[y¬∑log(≈∑) + (1-y)¬∑log(1-≈∑)]")
print("   Purpose: Binary classification (real vs fake)")

# ============================================================================
# QUESTION 1: DEFINE OPTIMIZERS
# ============================================================================
print("\n" + "="*60)
print("QUESTION 1: DEFINE OPTIMIZERS")
print("="*60)

optimizerD = optim.Adam(netD.parameters(), lr=lr_gan, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=lr_gan, betas=(beta1, 0.999))

print("‚úÖ Optimizers: Adam")
print(f"   Learning rate: {lr_gan}")
print(f"   Beta1 (momentum): {beta1}")
print("   Separate optimizers for Generator and Discriminator")

# Fixed noise for progress tracking
fixed_noise = torch.randn(64, nz, 1, 1, device=device)
print(f"\n‚úÖ Fixed noise created for tracking (shape: {fixed_noise.shape})")

# ============================================================================
# QUESTION 1: TRAINING LOOP
# ============================================================================
print("\n" + "="*60)
print("QUESTION 1: TRAINING GAN")
print("="*60)

print("""
Training Procedure:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
For each epoch:
  For each batch:
    1. Update Discriminator:
       ‚Ä¢ Train on real images ‚Üí label=1
       ‚Ä¢ Train on fake images ‚Üí label=0
       ‚Ä¢ Maximize: log(D(x)) + log(1-D(G(z)))

    2. Update Generator:
       ‚Ä¢ Generate fake images
       ‚Ä¢ Train to fool Discriminator
       ‚Ä¢ Maximize: log(D(G(z)))
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
""")

G_losses = []
D_losses = []
img_list = []

print(f"Starting training for {epochs_gan} epochs...")
print(f"Batches per epoch: {len(dataloader_gan)}\n")

for epoch in range(epochs_gan):
    for i, (real_imgs, _) in enumerate(dataloader_gan):
        real_imgs = real_imgs.to(device)
        b_size = real_imgs.size(0)

        # ================================================================
        # (1) UPDATE DISCRIMINATOR
        # ================================================================
        netD.zero_grad()

        # Train on REAL images
        label_real = torch.full((b_size,), 1., dtype=torch.float, device=device)
        output_real = netD(real_imgs)
        errD_real = criterion(output_real, label_real)
        errD_real.backward()
        D_x = output_real.mean().item()

        # Train on FAKE images
        noise = torch.randn(b_size, nz, 1, 1, device=device)
        fake = netG(noise)
        label_fake = torch.full((b_size,), 0., dtype=torch.float, device=device)
        output_fake = netD(fake.detach())
        errD_fake = criterion(output_fake, label_fake)
        errD_fake.backward()
        D_G_z1 = output_fake.mean().item()

        errD = errD_real + errD_fake
        optimizerD.step()

        # ================================================================
        # (2) UPDATE GENERATOR
        # ================================================================
        netG.zero_grad()
        label = torch.full((b_size,), 1., dtype=torch.float, device=device)
        output = netD(fake)
        errG = criterion(output, label)
        errG.backward()
        D_G_z2 = output.mean().item()
        optimizerG.step()

    # Save losses
    G_losses.append(errG.item())
    D_losses.append(errD.item())

    # Generate images from fixed noise
    with torch.no_grad():
        fake = netG(fixed_noise).detach().cpu()
    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))

    # Print progress
    if (epoch + 1) % 10 == 0 or epoch == 0:
        print(f"[{epoch+1:3d}/{epochs_gan}] Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} "
              f"D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f}/{D_G_z2:.4f}")

print("\n‚úÖ Training complete!\n")

# ============================================================================
# QUESTION 2: EVALUATE - PLOT LOSSES
# ============================================================================
print("="*60)
print("QUESTION 2: EVALUATE MODEL - LOSS PLOTS")
print("="*60)

plt.figure(figsize=(12, 5))
plt.plot(G_losses, label="Generator Loss", alpha=0.8, linewidth=2)
plt.plot(D_losses, label="Discriminator Loss", alpha=0.8, linewidth=2)
plt.xlabel("Epoch", fontsize=12)
plt.ylabel("Loss", fontsize=12)
plt.title("GAN Training Loss Evolution", fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("\nüìä LOSS ANALYSIS:")
print(f"   Final D_loss: {D_losses[-1]:.4f}")
print(f"   Final G_loss: {G_losses[-1]:.4f}")

if 0.3 <= D_losses[-1] <= 0.8:
    print("   ‚úÖ D_loss in healthy range")
else:
    print("   ‚ö†Ô∏è  D_loss outside ideal range")

print("\nüìù CONCLUSIONS:")
print("1. Oscillating losses = healthy competition")
print("2. D_loss ‚Üí 0: Discriminator too strong")
print("3. G_loss ‚Üí 0: Mode collapse")
print("4. Balanced losses indicate successful training")

# ============================================================================
# QUESTION 3: GENERATE NEW DATA & COMPARE
# ============================================================================
print("\n" + "="*60)
print("QUESTION 3: GENERATE NEW DATA & COMPARE QUALITY")
print("="*60)

# Generate new samples
num_samples = 64
with torch.no_grad():
    sample_noise = torch.randn(num_samples, nz, 1, 1, device=device)
    generated_images = netG(sample_noise).detach().cpu()

print(f"‚úÖ Generated {num_samples} new abstract art images\n")

# Side-by-side comparison
fig = plt.figure(figsize=(16, 8))

plt.subplot(1, 2, 1)
plt.axis("off")
plt.title("REAL Abstract Art", fontsize=14, fontweight='bold')
plt.imshow(np.transpose(
    vutils.make_grid(real_batch[:64], padding=2, normalize=True), (1, 2, 0)
))

plt.subplot(1, 2, 2)
plt.axis("off")
plt.title("GENERATED by GAN", fontsize=14, fontweight='bold')
plt.imshow(np.transpose(
    vutils.make_grid(generated_images[:64], padding=2, normalize=True), (1, 2, 0)
))

plt.tight_layout()
plt.show()

# Individual samples
fig, axes = plt.subplots(2, 8, figsize=(16, 4))
fig.suptitle('Quality Comparison: Real (Top) vs Generated (Bottom)',
             fontsize=14, fontweight='bold')

for i in range(8):
    real_img = (real_batch[i].cpu() + 1) / 2
    axes[0, i].imshow(np.transpose(real_img, (1, 2, 0)))
    axes[0, i].axis('off')

    fake_img = (generated_images[i] + 1) / 2
    axes[1, i].imshow(np.transpose(fake_img, (1, 2, 0)))
    axes[1, i].axis('off')

plt.tight_layout()
plt.show()

# Training evolution
print("\nüìà Generation quality evolution...")
num_display = min(6, len(img_list))
epoch_indices = np.linspace(0, len(img_list)-1, num_display, dtype=int)

fig, axes = plt.subplots(2, 3, figsize=(15, 10))
fig.suptitle('Generated Images Evolution During Training',
             fontsize=14, fontweight='bold')

for idx, epoch_idx in enumerate(epoch_indices):
    row = idx // 3
    col = idx % 3
    axes[row, col].axis("off")
    axes[row, col].set_title(f'Epoch {epoch_idx+1}', fontsize=12)
    axes[row, col].imshow(np.transpose(img_list[epoch_idx], (1, 2, 0)))

plt.tight_layout()
plt.show()

print("\n" + "="*70)
print("‚úÖ LAB 4 - PART 2 COMPLETE!")
print("="*70)
print("\nYou successfully:")
print("‚Ä¢ Downloaded Abstract Art dataset from Kaggle")
print("‚Ä¢ Built Generator and Discriminator (DCGAN)")
print("‚Ä¢ Trained GAN for", epochs_gan, "epochs")
print("‚Ä¢ Evaluated with loss plots")